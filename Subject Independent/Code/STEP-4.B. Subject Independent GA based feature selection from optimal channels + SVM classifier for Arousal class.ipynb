{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":9100,"status":"ok","timestamp":1644054073575,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"hR-yxs2d6d4Q","outputId":"f0ebadb0-f2a4-4049-ce27-c6b52a37e0ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting deap\n","  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n","Installing collected packages: deap\n","Successfully installed deap-1.3.1\n","Collecting scoop\n","  Downloading scoop-0.7.1.1.tar.gz (603 kB)\n","\u001b[K     |████████████████████████████████| 603 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from scoop) (1.1.2)\n","Requirement already satisfied: pyzmq>=13.1.0 in /usr/local/lib/python3.7/dist-packages (from scoop) (22.3.0)\n","Collecting argparse>=1.1\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Building wheels for collected packages: scoop\n","  Building wheel for scoop (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scoop: filename=scoop-0.7.1.1-py3-none-any.whl size=72141 sha256=33d2cc7cf890b1f5e53103a6d6a06fae23f3bf4dda076587a1e4b8381f53121f\n","  Stored in directory: /root/.cache/pip/wheels/24/19/e9/6e3e7c0323cc36bf1e4993d69b2db27d6b4e806ed57d411f44\n","Successfully built scoop\n","Installing collected packages: argparse, scoop\n","Successfully installed argparse-1.4.0 scoop-0.7.1.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{},"output_type":"display_data"}],"source":["! pip install deap\n","! pip install scoop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2129,"status":"ok","timestamp":1644054159532,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"UYpJjc9j6FKL","outputId":"c2d90784-811c-4cee-e2ba-1929870e5529"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import sklearn.model_selection as model_selection\n","import pickle, scipy, csv, statistics, math, warnings, joblib, random, numpy\n","from sklearn import metrics, svm, datasets\n","from math import log,e, floor\n","from time import time\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.model_selection import cross_val_score,cross_val_predict,GridSearchCV, train_test_split, StratifiedKFold, KFold, cross_validate, learning_curve\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n","from sklearn.metrics import plot_confusion_matrix, mean_absolute_error,accuracy_score,r2_score,confusion_matrix ,classification_report, f1_score, precision_score, recall_score\n","from sklearn import metrics, preprocessing, svm\n","from sklearn.linear_model import LogisticRegression\n","from deap import creator, base, tools, algorithms\n","from scoop import futures\n","from sklearn.utils import shuffle\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import warnings\n","if not sys.warnoptions:\n","  warnings.simplefilter(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27926,"status":"ok","timestamp":1644054195484,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"xpDM7M7a9poR","outputId":"9530cae6-ef42-44d3-dc8e-2221b6f75ffe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":985,"status":"ok","timestamp":1644054206024,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"Qt6asTSB6N-h","outputId":"92a2cdc5-35f2-4349-847d-4f326072d34c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Sequential methods for channel selection/Subject Independent/data files/Wavelet Based\n"]}],"source":["cd /content/drive/MyDrive/Sequential methods for channel selection/Subject Independent/data files/Wavelet Based/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1644054207531,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"zMgsGqLy6Uhf","outputId":"375b3255-fee8-46d9-c297-5c323d3f9a4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["s01_arousal.csv      s11_valence.csv\t  s22_new_arousal.csv\n","s01_FourClass.csv    s12_arousal.csv\t  s22_valence.csv\n","s01_new_arousal.csv  s12_FourClass.csv\t  s23_arousal.csv\n","s01_valence.csv      s12_new_arousal.csv  s23_FourClass.csv\n","s02_arousal.csv      s12_valence.csv\t  s23_new_arousal.csv\n","s02_FourClass.csv    s13_arousal.csv\t  s23_valence.csv\n","s02_new_arousal.csv  s13_FourClass.csv\t  s24_arousal.csv\n","s02_valence.csv      s13_new_arousal.csv  s24_FourClass.csv\n","s03_arousal.csv      s13_valence.csv\t  s24_new_arousal.csv\n","s03_FourClass.csv    s14_arousal.csv\t  s24_valence.csv\n","s03_new_arousal.csv  s14_FourClass.csv\t  s25_arousal.csv\n","s03_valence.csv      s14_new_arousal.csv  s25_FourClass.csv\n","s04_arousal.csv      s14_valence.csv\t  s25_new_arousal.csv\n","s04_FourClass.csv    s15_arousal.csv\t  s25_valence.csv\n","s04_new_arousal.csv  s15_FourClass.csv\t  s26_arousal.csv\n","s04_valence.csv      s15_new_arousal.csv  s26_FourClass.csv\n","s05_arousal.csv      s15_valence.csv\t  s26_new_arousal.csv\n","s05_FourClass.csv    s16_arousal.csv\t  s26_valence.csv\n","s05_new_arousal.csv  s16_FourClass.csv\t  s27_arousal.csv\n","s05_valence.csv      s16_new_arousal.csv  s27_FourClass.csv\n","s06_arousal.csv      s16_valence.csv\t  s27_new_arousal.csv\n","s06_FourClass.csv    s17_arousal.csv\t  s27_valence.csv\n","s06_new_arousal.csv  s17_FourClass.csv\t  s28_arousal.csv\n","s06_valence.csv      s17_new_arousal.csv  s28_FourClass.csv\n","s07_arousal.csv      s17_valence.csv\t  s28_new_arousal.csv\n","s07_FourClass.csv    s18_arousal.csv\t  s28_valence.csv\n","s07_new_arousal.csv  s18_FourClass.csv\t  s29_arousal.csv\n","s07_valence.csv      s18_new_arousal.csv  s29_FourClass.csv\n","s08_arousal.csv      s18_valence.csv\t  s29_new_arousal.csv\n","s08_FourClass.csv    s19_arousal.csv\t  s29_valence.csv\n","s08_new_arousal.csv  s19_FourClass.csv\t  s30_arousal.csv\n","s08_valence.csv      s19_new_arousal.csv  s30_FourClass.csv\n","s09_arousal.csv      s19_valence.csv\t  s30_new_arousal.csv\n","s09_FourClass.csv    s20_arousal.csv\t  s30_valence.csv\n","s09_new_arousal.csv  s20_FourClass.csv\t  s31_arousal.csv\n","s09_valence.csv      s20_new_arousal.csv  s31_FourClass.csv\n","s10_arousal.csv      s20_valence.csv\t  s31_new_arousal.csv\n","s10_FourClass.csv    s21_arousal.csv\t  s31_valence.csv\n","s10_new_arousal.csv  s21_FourClass.csv\t  s32_arousal.csv\n","s10_valence.csv      s21_new_arousal.csv  s32_FourClass.csv\n","s11_arousal.csv      s21_valence.csv\t  s32_new_arousal.csv\n","s11_FourClass.csv    s22_arousal.csv\t  s32_valence.csv\n","s11_new_arousal.csv  s22_FourClass.csv\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3ULU-z8dNFX"},"outputs":[],"source":["def emotion_label(labels, class_label):\n","\tem_labels = []\n","\tif(class_label == \"valence\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low valence\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"arousal\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][1]>5): # high arousal\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low arousal\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"all\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(1) # HVHA\n","\t\t\t\telse:\n","\t\t\t\t\tem_labels.append(0) # HVLA\n","\t\t\telse: # low valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(2) # LVHA\n","\t\t\t\telse: # low arousal\n","\t\t\t\t\tem_labels.append(3) # LVLA\n","\t\treturn em_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cS0m53fZ7LhK"},"outputs":[],"source":["def kfold(allFeatures, allClasses, index):\n","    m = int(allClasses.shape[0])\n","    s = int(m/10)\n","    train_index = np.ones(m-s+1).astype(int)\n","    test_index  = np.ones(s).astype(int)\n","    for i in range(s*index,s*(index+1)):\n","        test_index[i-s*index] = i\n","    for i in range(0,s*index):\n","        train_index[i] = i\n","    for i in range(s + s*index,m):\n","        train_index[i-s] = i\n","    X_train = allFeatures.iloc[train_index]\n","    X_test = allFeatures.iloc[test_index]\n","    y_train = allClasses[train_index]\n","    y_test = allClasses[test_index]\n","    # normalize the xtrain data only with class labels\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOgm0TEtANY3"},"outputs":[],"source":["# Feature subset fitness function\n","def getFitness(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    parse our feature columns that we don't use\n","    apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    return (accuracy,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvZAc8yv8UMt"},"outputs":[],"source":["def getFitness_all(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Feature subset fitness function\n","    Parse our feature columns that we don't use\n","    Apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    #print(cols)\n","    #print(cols.shape)\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    return (accuracy, )\n","\n","def getFinal(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Feature subset fitness function\n","    Parse our feature columns that we don't use\n","    Apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    #print(cols)\n","    #print(cols.shape)\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    ps = precision_score(y_test, predictions)*100\n","    rs = recall_score(y_test, predictions)*100\n","    f1 = f1_score(y_test, predictions)*100\n","    return accuracy, ps, rs, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtVNGpokANb_"},"outputs":[],"source":["def getHof(toolbox):\n","    # Initialize variables to use eaSimple\n","    numPop = 100\n","    numGen = 50\n","    pop = toolbox.population(n=numPop)\n","    hof = tools.HallOfFame(numPop * numGen)\n","    stats = tools.Statistics(lambda ind: ind.fitness.values)\n","    stats.register(\"avg\", numpy.mean)\n","    stats.register(\"std\", numpy.std)\n","    stats.register(\"min\", numpy.min)\n","    stats.register(\"max\", numpy.max)\n","\n","    # Launch genetic algorithm\n","    # change the crossover and mutation probability\n","    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.65, mutpb=0.001, ngen=numGen, stats=stats, halloffame=hof, verbose=False)\n","    # Return the hall of fame\n","    return hof,log"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD9A156cANen"},"outputs":[],"source":["def getMetrics(hof, X_train, X_test, y_train, y_test):\n","    # Get list of percentiles in the hall of fame\n","    percentileList = [i / (len(hof) - 1) for i in range(len(hof))]\n","    # Gather fitness data from each percentile\n","    testAccuracyList = []\n","    validationAccuracyList = []\n","    individualList = []\n","    for individual in hof:\n","        testAccuracy = individual.fitness.values\n","        validationAccuracy = getFitness(individual, X_train, X_test, y_train, y_test)\n","        testAccuracyList.append(testAccuracy[0])\n","        validationAccuracyList.append(validationAccuracy[0])\n","        individualList.append(individual)\n","    #testAccuracyList.reverse()\n","    #validationAccuracyList.reverse()\n","    return testAccuracyList, validationAccuracyList, individualList, percentileList"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmWt9S-B6gAm"},"outputs":[],"source":["def drive(subject_name):\n","  dfData = pd.read_csv(subject_name + '_new_arousal.csv')\n","  allFeatures = dfData\n","  names = allFeatures.columns\n","  scaler = MinMaxScaler()\n","  allFeatures = scaler.fit_transform(allFeatures)\n","  allFeatures = pd.DataFrame(allFeatures, columns=names)\n","  allFeatures = allFeatures.loc[:, allFeatures.apply(pd.Series.nunique) != 1]\n","  link = \"/content/drive/MyDrive/Deap/\" + subject_name + \".dat\"\n","  with open(link, 'rb') as f:\n","    raw_data = pickle.load(f, encoding = 'latin1')\n","  labels = raw_data['labels']\n","  em_labels = emotion_label(labels, 'arousal') # get the emotion labels\n","  allClasses = np.array(em_labels)\n","  allFeatures, allClasses = shuffle(allFeatures, allClasses, random_state = 40)\n","  return allFeatures, allClasses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RK82L6_S8Jgn"},"outputs":[],"source":["subject_names = [\"s01\", \"s02\", \"s03\", \"s04\", \"s05\", \"s06\", \"s07\", \"s08\", \"s09\", \"s10\", \"s11\", \"s12\",\n","                 \"s13\", \"s14\", \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\",\n","                \"s22\", \"s23\", \"s24\", \"s25\", \"s26\", \"s27\", \"s28\", \"s29\", \"s30\", \"s31\", \"s32\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9oFiOjcAZot"},"outputs":[],"source":["def main_code(allFeatures, allClasses):\n","  print(\"\\nFold\\tAccuracy_with_all_features\\tAccuracy\\tPrecision\\tRecall\\tF1-Score\")\n","  acc_fs, pre_fs, recall_fs, f1_fs, all_acc = np.ones(10), np.ones(10), np.ones(10), np.ones(10), np.ones(10)\n","  for i in range(0, 10):\n","    #call k fold\n","    X_train, X_test, y_train, y_test = kfold(allFeatures, allClasses, i)\n","    #==========================    DEAP GLOBAL VARIABLES (viewable by SCOOP)      ======================\n","    # Create Individual\n","    creator.create(\"FitnessMax\", base.Fitness, weights = (1.0,))\n","    creator.create(\"Individual\", list, fitness = creator.FitnessMax)\n","    # Create Toolbox\n","    toolbox = base.Toolbox()\n","    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(allFeatures.columns) - 1)\n","    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","    # Continue filling toolbox...\n","    toolbox.register(\"evaluate\", getFitness, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test)\n","    toolbox.register(\"mate\", tools.cxOnePoint)\n","    toolbox.register(\"mutate\", tools.mutFlipBit, indpb = 0.05)\n","    toolbox.register(\"select\", tools.selTournament, tournsize = 7)\n","    #===================================================================================================\n","    # First, we will apply SVM using all the features to acquire a baseline accuracy.\n","    individual = [1 for i in range(len(allFeatures.columns))]\n","    Accuracy = getFitness_all(individual, X_train, X_test, y_train, y_test)\n","    all_acc[i] = Accuracy[0]\n","    if(all_acc[i]==100):\n","      acc_fs[i], pre_fs[i], recall_fs[i], f1_fs[i]  = Accuracy[0], Accuracy[0], Accuracy[0], Accuracy[0]\n","      print(i+1,\"\\t\\t%.2f\"%all_acc[i], \"\\t\\t\\t%.2f\"%acc_fs[i], \"\\t\\t%.2f\"%pre_fs[i], \"\\t\\t%.2f\"%recall_fs[i], \"\\t%.2f\"%f1_fs[i])\n","      continue\n","    #=====================================================================================================\n","    # Now, we will apply a genetic algorithm to choose a subset of features that gives a better accuracy than the baseline.\n","    hof, log = getHof(toolbox)\n","    best_indivisual = list(hof)[0]\n","    accuracy, ps, rs, f1 = getFinal(best_indivisual, X_train, X_test, y_train, y_test)\n","    if(ps == 0):\n","      ps, rs, f1 = accuracy, accuracy, accuracy\n","    acc_fs[i], pre_fs[i], recall_fs[i], f1_fs[i] = accuracy, ps, rs, f1\n","    print(i+1,\"\\t\\t%.2f\"%all_acc[i], \"\\t\\t\\t%.2f\"%acc_fs[i], \"\\t\\t%.2f\"%pre_fs[i], \"\\t\\t%.2f\"%recall_fs[i], \"\\t%.2f\"%f1_fs[i])\n","  print(\"-\"*100)\n","  print(\"Total\",\"\\t\\t%.2f\"%np.mean(all_acc), \"\\t\\t\\t%.2f\"%np.mean(acc_fs), \"\\t\\t%.2f\"%np.mean(pre_fs), \"\\t\\t%.2f\"%np.mean(recall_fs), \"\\t%.2f\"%np.mean(f1_fs))\n","  print(\"-\"*100)\n","  print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qKwW930Vd8X2"},"outputs":[],"source":["for i in range(16,20):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31NdZ0Tja4ao"},"outputs":[],"source":["for i in range(8,12):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haj9GzL5kdir"},"outputs":[],"source":["for i in range(24, 32):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"markdown","metadata":{"id":"1hzei03Hitd1"},"source":["**Accuracy**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1644080173509,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"PpC5h5t1s32y","outputId":"3bf4ab1a-aa18-4287-c20c-73fcb6c0fd77"},"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","85.0\n","5.038911092686593\n"]}],"source":["import numpy as np\n","accuracy = [92.50, 82.50, 87.50, 80.00, 77.50, 87.50, 85.00, 87.50, 75.00, 92.50, 85.00, 90.00,  90.00,  87.50, 80.00, 92.50, 85.00, 85.00, 80.00,\\\n","            82.50, 82.50, 77.50, 90.00, 92.50, 77.50, 77.50, 82.50, 87.50, 85.00, 92.50, 85.00, 85.00]\n","print(len(accuracy))\n","accuracy = np.array(accuracy)\n","print(np.mean(accuracy))\n","print(np.std(accuracy))"]},{"cell_type":"markdown","metadata":{"id":"CnCh3SgQQ1qh"},"source":["**Precision**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1644080485519,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"D_0mgcIcij3W","outputId":"1d67b773-362e-4677-9f46-a67815ef0ed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","87.78718749999999\n","4.610355351254798\n"]}],"source":["precision = [90.00 ,89.17,92.50,87.50,82.50,89.17,86.67,89.17,80.00,91.67,87.50,89.17 ,89.17 ,89.17,85.00,97.50,95.00,88.33,81.67,84.17,83.33,77.50,\\\n","             92.50,90.00 ,78.33,83.33,86.67,92.50,88.33,94.17,90.0, 87.50]\n","print(len(precision))\n","precision = np.array(precision)\n","print(np.mean(precision))\n","print(np.std(precision))"]},{"cell_type":"markdown","metadata":{"id":"vYHYosARiwOS"},"source":["**Recall or sensitivity**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":700,"status":"ok","timestamp":1644080584923,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"T_QkO7J2lfik","outputId":"59768fb6-0315-4797-8ed9-d07677ee10c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["90.65156250000001\n"]},{"output_type":"execute_result","data":{"text/plain":["6.5843185435999185"]},"metadata":{},"execution_count":6}],"source":["recall = [100.00,84.17 ,84.17 ,74.17 ,80.00 ,90.83 ,91.67 ,91.67 ,75.83 ,95.00 ,86.67 ,100.00, 100.00, 96.67 ,85.00 ,90.00 ,85.83 ,95.00 ,94.17 ,96.67,\\\n","          96.67 ,92.50 ,87.50 ,100.00, 92.50 ,83.33 ,93.33 ,88.33 ,94.17 ,92.50 ,88.33 ,94.17]\n","recall = np.array(recall)\n","print(np.mean(recall))\n","np.std(recall)"]},{"cell_type":"markdown","metadata":{"id":"NLYj-mQVe_Xf"},"source":["**f1-Score**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1644080340829,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"e38D0Ecsmr-U","outputId":"45d084b7-85e0-4be4-df88-9f450f7f319b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(32,)\n","87.02906250000001\n","5.09195588611034\n"]}],"source":["f1 = [94.00, 84.81, 87.17, 77.17, 78.17, 87.17, 87.14, 88.74, 74.40, 93.00, 84.07, 93.71, 93.71, 92.38, 80.00, 91.90, 86.90, 89.33, 84.64, 88.38,\\\n","      88.95, 79.90, 89.17, 93.00, 83.38, 81.00, 88.48, 86.90, 89.71, 92.17, 85.67, 89.81]\n","f1 = np.array(f1)\n","print(f1.shape)\n","print(np.mean(f1))\n","print(np.std(f1))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"STEP: 4B-- Subject Independent GA based feature selection from optimal channels + SVM classifier for Arousal class.ipynb","provenance":[{"file_id":"1HYesvxoVn-s8CHSqqMROc-FaB65YAOUe","timestamp":1640784913180},{"file_id":"1HLyqqmh4klsQ8H-0e4Eq499vAupq5dS0","timestamp":1639306093118},{"file_id":"1KXk5nWjSgHzZ6ccp66jHRDZI4bJMslHn","timestamp":1639196338642},{"file_id":"1yUzEFwdmCNH_qb7NPCgLlYElOhT12erL","timestamp":1634187566670},{"file_id":"1SPeDVHCHi4uFuamkolvaep7nGU7mOyiv","timestamp":1634152149383},{"file_id":"1aD6aXmoab59Jb7cxRTbtGKDfdiG7ianV","timestamp":1634151736936},{"file_id":"1luLhv4lQ-SruSeQqeX8bZnYPR-_TYxDk","timestamp":1634111894346},{"file_id":"11OHLRm15JjC9C-Y-R_LGBacQkwDFduQh","timestamp":1633972949871},{"file_id":"1qrk7-0VYo258YnzRzG4ztcbrT3zWq-HG","timestamp":1633964775809}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}