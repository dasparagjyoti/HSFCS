{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":11564,"status":"ok","timestamp":1643992690341,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"hR-yxs2d6d4Q","outputId":"f5a41b1e-1be8-46b7-b99b-ca5e3271ecd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting deap\n","  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n","Installing collected packages: deap\n","Successfully installed deap-1.3.1\n","Collecting scoop\n","  Downloading scoop-0.7.1.1.tar.gz (603 kB)\n","\u001b[K     |████████████████████████████████| 603 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from scoop) (1.1.2)\n","Requirement already satisfied: pyzmq>=13.1.0 in /usr/local/lib/python3.7/dist-packages (from scoop) (22.3.0)\n","Collecting argparse>=1.1\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Building wheels for collected packages: scoop\n","  Building wheel for scoop (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scoop: filename=scoop-0.7.1.1-py3-none-any.whl size=72141 sha256=9dd2862f37fd170a28ea130aedfbac5d663820ec7e0c8afa95a7738cc9280120\n","  Stored in directory: /root/.cache/pip/wheels/24/19/e9/6e3e7c0323cc36bf1e4993d69b2db27d6b4e806ed57d411f44\n","Successfully built scoop\n","Installing collected packages: argparse, scoop\n","Successfully installed argparse-1.4.0 scoop-0.7.1.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{},"output_type":"display_data"}],"source":["! pip install deap\n","! pip install scoop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2263,"status":"ok","timestamp":1643992692594,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"UYpJjc9j6FKL","outputId":"d4493590-5a21-4e3e-f292-f1b4afe0033e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import sklearn.model_selection as model_selection\n","import pickle, scipy, csv, statistics, math, warnings, joblib, random, numpy\n","from sklearn import metrics, svm, datasets\n","from math import log,e, floor\n","from time import time\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.model_selection import cross_val_score,cross_val_predict,GridSearchCV, train_test_split, StratifiedKFold, KFold, cross_validate, learning_curve\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n","from sklearn.metrics import plot_confusion_matrix, mean_absolute_error,accuracy_score,r2_score,confusion_matrix ,classification_report, f1_score, precision_score, recall_score\n","from sklearn import metrics, preprocessing, svm\n","from sklearn.linear_model import LogisticRegression\n","from deap import creator, base, tools, algorithms\n","from scoop import futures\n","from sklearn.utils import shuffle\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import warnings\n","if not sys.warnoptions:\n","  warnings.simplefilter(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21623,"status":"ok","timestamp":1643992714211,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"xpDM7M7a9poR","outputId":"ad793d23-4c92-44fe-a7ed-dee7592a7fcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":750,"status":"ok","timestamp":1643992714954,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"Qt6asTSB6N-h","outputId":"025e55d3-c909-40c8-b1b7-1541c27ef41c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Sequential methods for channel selection/Subject Independent/data files/Wavelet Based\n"]}],"source":["cd /content/drive/MyDrive/Sequential methods for channel selection/Subject Independent/data files/Wavelet Based/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1643992154456,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"zMgsGqLy6Uhf","outputId":"f61c7eb0-6cba-4217-ce63-8c86833f1c1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["s01_arousal.csv      s11_new_arousal.csv  s23_arousal.csv\n","s01_FourClass.csv    s11_valence.csv\t  s23_FourClass.csv\n","s01_new_arousal.csv  s12_arousal.csv\t  s23_new_arousal.csv\n","s01_valence.csv      s12_FourClass.csv\t  s23_valence.csv\n","s02_arousal.csv      s12_new_arousal.csv  s24_arousal.csv\n","s02_FourClass.csv    s12_valence.csv\t  s24_FourClass.csv\n","s02_new_arousal.csv  s13_arousal.csv\t  s24_new_arousal.csv\n","s02_valence.csv      s13_FourClass.csv\t  s24_valence.csv\n","s03_arousal.csv      s13_new_arousal.csv  s25_arousal.csv\n","s03_FourClass.csv    s13_valence.csv\t  s25_FourClass.csv\n","s03_new_arousal.csv  s14_arousal.csv\t  s25_new_arousal.csv\n","s03_valence.csv      s14_FourClass.csv\t  s25_valence.csv\n","s04_arousal.csv      s14_new_arousal.csv  s26_arousal.csv\n","s04_FourClass.csv    s14_valence.csv\t  s26_FourClass.csv\n","s04_new_arousal.csv  s15_arousal.csv\t  s26_new_arousal.csv\n","s04_valence.csv      s15_FourClass.csv\t  s26_valence.csv\n","s05_arousal.csv      s15_new_arousal.csv  s27_arousal.csv\n","s05_FourClass.csv    s15_valence.csv\t  s27_FourClass.csv\n","s05_new_arousal.csv  s16_arousal.csv\t  s27_new_arousal.csv\n","s05_valence.csv      s16_FourClass.csv\t  s27_valence.csv\n","s06_arousal.csv      s16_new_arousal.csv  s28_arousal.csv\n","s06_FourClass.csv    s16_valence.csv\t  s28_FourClass.csv\n","s06_new_arousal.csv  s17_arousal.csv\t  s28_new_arousal.csv\n","s06_valence.csv      s17_FourClass.csv\t  s28_valence.csv\n","s07_arousal.csv      s17_valence.csv\t  s29_arousal.csv\n","s07_FourClass.csv    s18_arousal.csv\t  s29_FourClass.csv\n","s07_new_arousal.csv  s18_FourClass.csv\t  s29_new_arousal.csv\n","s07_valence.csv      s18_valence.csv\t  s29_valence.csv\n","s08_arousal.csv      s19_arousal.csv\t  s30_arousal.csv\n","s08_FourClass.csv    s19_FourClass.csv\t  s30_FourClass.csv\n","s08_new_arousal.csv  s19_valence.csv\t  s30_new_arousal.csv\n","s08_valence.csv      s20_arousal.csv\t  s30_valence.csv\n","s09_arousal.csv      s20_FourClass.csv\t  s31_arousal.csv\n","s09_FourClass.csv    s20_valence.csv\t  s31_FourClass.csv\n","s09_new_arousal.csv  s21_arousal.csv\t  s31_new_arousal.csv\n","s09_valence.csv      s21_FourClass.csv\t  s31_valence.csv\n","s10_arousal.csv      s21_new_arousal.csv  s32_arousal.csv\n","s10_FourClass.csv    s21_valence.csv\t  s32_FourClass.csv\n","s10_new_arousal.csv  s22_arousal.csv\t  s32_new_arousal.csv\n","s10_valence.csv      s22_FourClass.csv\t  s32_valence.csv\n","s11_arousal.csv      s22_new_arousal.csv\n","s11_FourClass.csv    s22_valence.csv\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3ULU-z8dNFX"},"outputs":[],"source":["def emotion_label(labels, class_label):\n","\tem_labels = []\n","\tif(class_label == \"valence\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low valence\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"arousal\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][1]>5): # high arousal\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low arousal\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"all\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(1) # HVHA\n","\t\t\t\telse:\n","\t\t\t\t\tem_labels.append(0) # HVLA\n","\t\t\telse: # low valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(2) # LVHA\n","\t\t\t\telse: # low arousal\n","\t\t\t\t\tem_labels.append(3) # LVLA\n","\t\treturn em_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cS0m53fZ7LhK"},"outputs":[],"source":["def kfold(allFeatures, allClasses, index):\n","    m = int(allClasses.shape[0])\n","    s = int(m/10)\n","    train_index = np.ones(m-s+1).astype(int)\n","    test_index  = np.ones(s).astype(int)\n","    for i in range(s*index,s*(index+1)):\n","        test_index[i-s*index] = i\n","    for i in range(0,s*index):\n","        train_index[i] = i\n","    for i in range(s + s*index,m):\n","        train_index[i-s] = i\n","    X_train = allFeatures.iloc[train_index]\n","    X_test = allFeatures.iloc[test_index]\n","    y_train = allClasses[train_index]\n","    y_test = allClasses[test_index]\n","    # normalize the xtrain data only with class labels\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOgm0TEtANY3"},"outputs":[],"source":["# Feature subset fitness function\n","def getFitness(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    parse our feature columns that we don't use\n","    apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    return (accuracy,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvZAc8yv8UMt"},"outputs":[],"source":["def getFitness_all(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Feature subset fitness function\n","    Parse our feature columns that we don't use\n","    Apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    #print(cols)\n","    #print(cols.shape)\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    return (accuracy, )\n","\n","def getFinal(individual, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Feature subset fitness function\n","    Parse our feature columns that we don't use\n","    Apply one hot encoding to the features.\n","    \"\"\"\n","    cols = [index for index in range(len(individual)) if individual[index] == 0]\n","    #print(cols)\n","    #print(cols.shape)\n","    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n","    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n","    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n","    X_testOhFeatures = pd.get_dummies(X_testParsed)\n","\n","    # Remove any columns that aren't in both the training and test sets\n","    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n","    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n","    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n","    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n","    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n","\n","    # Apply logistic regression on the data, and calculate accuracy\n","    clf = svm.SVC(kernel='poly').fit(X_trainOhFeatures, y_train)\n","    predictions = clf.predict(X_testOhFeatures)\n","    accuracy = accuracy_score(y_test, predictions)*100\n","    ps = precision_score(y_test, predictions)*100\n","    rs = recall_score(y_test, predictions)*100\n","    f1 = f1_score(y_test, predictions)*100\n","    return accuracy, ps, rs, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtVNGpokANb_"},"outputs":[],"source":["def getHof(toolbox):\n","    # Initialize variables to use eaSimple\n","    numPop = 100\n","    numGen = 50\n","    pop = toolbox.population(n=numPop)\n","    hof = tools.HallOfFame(numPop * numGen)\n","    stats = tools.Statistics(lambda ind: ind.fitness.values)\n","    stats.register(\"avg\", numpy.mean)\n","    stats.register(\"std\", numpy.std)\n","    stats.register(\"min\", numpy.min)\n","    stats.register(\"max\", numpy.max)\n","\n","    # Launch genetic algorithm\n","    # change the crossover and mutation probability\n","    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.65, mutpb=0.001, ngen=numGen, stats=stats, halloffame=hof, verbose=False)\n","    # Return the hall of fame\n","    return hof,log"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD9A156cANen"},"outputs":[],"source":["def getMetrics(hof, X_train, X_test, y_train, y_test):\n","    # Get list of percentiles in the hall of fame\n","    percentileList = [i / (len(hof) - 1) for i in range(len(hof))]\n","    # Gather fitness data from each percentile\n","    testAccuracyList = []\n","    validationAccuracyList = []\n","    individualList = []\n","    for individual in hof:\n","        testAccuracy = individual.fitness.values\n","        validationAccuracy = getFitness(individual, X_train, X_test, y_train, y_test)\n","        testAccuracyList.append(testAccuracy[0])\n","        validationAccuracyList.append(validationAccuracy[0])\n","        individualList.append(individual)\n","    #testAccuracyList.reverse()\n","    #validationAccuracyList.reverse()\n","    return testAccuracyList, validationAccuracyList, individualList, percentileList"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmWt9S-B6gAm"},"outputs":[],"source":["def drive(subject_name):\n","  dfData = pd.read_csv(subject_name + '_new_arousal.csv')\n","  allFeatures = dfData\n","  names = allFeatures.columns\n","  scaler = MinMaxScaler()\n","  allFeatures = scaler.fit_transform(allFeatures)\n","  allFeatures = pd.DataFrame(allFeatures, columns=names)\n","  allFeatures = allFeatures.loc[:, allFeatures.apply(pd.Series.nunique) != 1]\n","  link = \"/content/drive/MyDrive/Deap/\" + subject_name + \".dat\"\n","  with open(link, 'rb') as f:\n","    raw_data = pickle.load(f, encoding = 'latin1')\n","  labels = raw_data['labels']\n","  em_labels = emotion_label(labels, 'arousal') # get the emotion labels\n","  allClasses = np.array(em_labels)\n","  allFeatures, allClasses = shuffle(allFeatures, allClasses, random_state = 40)\n","  return allFeatures, allClasses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RK82L6_S8Jgn"},"outputs":[],"source":["subject_names = [\"s01\", \"s02\", \"s03\", \"s04\", \"s05\", \"s06\", \"s07\", \"s08\", \"s09\", \"s10\", \"s11\", \"s12\",\n","                 \"s13\", \"s14\", \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\",\n","                \"s22\", \"s23\", \"s24\", \"s25\", \"s26\", \"s27\", \"s28\", \"s29\", \"s30\", \"s31\", \"s32\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9oFiOjcAZot"},"outputs":[],"source":["def main_code(allFeatures, allClasses):\n","  print(\"\\nFold\\tAccuracy_with_all_features\\tAccuracy\\tPrecision\\tRecall\\tF1-Score\")\n","  acc_fs, pre_fs, recall_fs, f1_fs, all_acc = np.ones(10), np.ones(10), np.ones(10), np.ones(10), np.ones(10)\n","  for i in range(0, 10):\n","    #call k fold\n","    X_train, X_test, y_train, y_test = kfold(allFeatures, allClasses, i)\n","    #==========================    DEAP GLOBAL VARIABLES (viewable by SCOOP)      ======================\n","    # Create Individual\n","    creator.create(\"FitnessMax\", base.Fitness, weights = (1.0,))\n","    creator.create(\"Individual\", list, fitness = creator.FitnessMax)\n","    # Create Toolbox\n","    toolbox = base.Toolbox()\n","    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(allFeatures.columns) - 1)\n","    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","    # Continue filling toolbox...\n","    toolbox.register(\"evaluate\", getFitness, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test)\n","    toolbox.register(\"mate\", tools.cxOnePoint)\n","    toolbox.register(\"mutate\", tools.mutFlipBit, indpb = 0.05)\n","    toolbox.register(\"select\", tools.selTournament, tournsize = 7)\n","    #===================================================================================================\n","    # First, we will apply SVM using all the features to acquire a baseline accuracy.\n","    individual = [1 for i in range(len(allFeatures.columns))]\n","    Accuracy = getFitness_all(individual, X_train, X_test, y_train, y_test)\n","    all_acc[i] = Accuracy[0]\n","    if(all_acc[i]==100):\n","      acc_fs[i], pre_fs[i], recall_fs[i], f1_fs[i]  = Accuracy[0], Accuracy[0], Accuracy[0], Accuracy[0]\n","      print(i+1,\"\\t\\t%.2f\"%all_acc[i], \"\\t\\t\\t%.2f\"%acc_fs[i], \"\\t\\t%.2f\"%pre_fs[i], \"\\t\\t%.2f\"%recall_fs[i], \"\\t%.2f\"%f1_fs[i])\n","      continue\n","    #=====================================================================================================\n","    # Now, we will apply a genetic algorithm to choose a subset of features that gives a better accuracy than the baseline.\n","    hof, log = getHof(toolbox)\n","    best_indivisual = list(hof)[0]\n","    accuracy, ps, rs, f1 = getFinal(best_indivisual, X_train, X_test, y_train, y_test)\n","    if(ps == 0):\n","      ps, rs, f1 = accuracy, accuracy, accuracy\n","    acc_fs[i], pre_fs[i], recall_fs[i], f1_fs[i] = accuracy, ps, rs, f1\n","    print(i+1,\"\\t\\t%.2f\"%all_acc[i], \"\\t\\t\\t%.2f\"%acc_fs[i], \"\\t\\t%.2f\"%pre_fs[i], \"\\t\\t%.2f\"%recall_fs[i], \"\\t%.2f\"%f1_fs[i])\n","  print(\"-\"*100)\n","  print(\"Total\",\"\\t\\t%.2f\"%np.mean(all_acc), \"\\t\\t\\t%.2f\"%np.mean(acc_fs), \"\\t\\t%.2f\"%np.mean(pre_fs), \"\\t\\t%.2f\"%np.mean(recall_fs), \"\\t%.2f\"%np.mean(f1_fs))\n","  print(\"-\"*100)\n","  print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qKwW930Vd8X2","outputId":"5a6eab21-e6d4-4c9b-d327-3002a86487df"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Subject No:  s21\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","2 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","3 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","4 \t\t50.00 \t\t\t50.00 \t\t66.67 \t\t66.67 \t66.67\n","5 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","7 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","9 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t77.50 \t\t\t82.50 \t\t83.33 \t\t96.67 \t88.95\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s22\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","2 \t\t25.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","3 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","4 \t\t75.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","5 \t\t50.00 \t\t\t75.00 \t\t50.00 \t\t100.00 \t66.67\n","6 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","7 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t25.00 \t\t\t25.00 \t\t100.00 \t\t25.00 \t40.00\n","9 \t\t25.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","10 \t\t50.00 \t\t\t75.00 \t\t50.00 \t\t100.00 \t66.67\n","----------------------------------------------------------------------------------------------------\n","Total \t\t52.50 \t\t\t77.50 \t\t77.50 \t\t92.50 \t79.90\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s23\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","3 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","4 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","5 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","7 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t50.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","9 \t\t50.00 \t\t\t75.00 \t\t100.00 \t\t50.00 \t66.67\n","10 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t72.50 \t\t\t90.00 \t\t92.50 \t\t87.50 \t89.17\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s24\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","3 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","4 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","5 \t\t25.00 \t\t\t50.00 \t\t33.33 \t\t100.00 \t50.00\n","6 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","7 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","9 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t85.00 \t\t\t92.50 \t\t90.00 \t\t100.00 \t93.00\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s25\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t50.00 \t\t\t50.00 \t\t50.00 \t\t100.00 \t66.67\n","2 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","3 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","4 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","5 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","6 \t\t50.00 \t\t\t50.00 \t\t50.00 \t\t50.00 \t50.00\n","7 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","9 \t\t25.00 \t\t\t75.00 \t\t100.00 \t\t75.00 \t85.71\n","10 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t60.00 \t\t\t77.50 \t\t78.33 \t\t92.50 \t83.38\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s26\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t0.00 \t\t\t50.00 \t\t66.67 \t\t66.67 \t66.67\n","3 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","4 \t\t50.00 \t\t\t75.00 \t\t100.00 \t\t66.67 \t80.00\n","5 \t\t75.00 \t\t\t75.00 \t\t50.00 \t\t100.00 \t66.67\n","6 \t\t50.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","7 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","9 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t50.00 \t\t\t50.00 \t\t100.00 \t\t50.00 \t66.67\n","----------------------------------------------------------------------------------------------------\n","Total \t\t52.50 \t\t\t77.50 \t\t83.33 \t\t83.33 \t81.00\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s27\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","3 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","4 \t\t25.00 \t\t\t50.00 \t\t50.00 \t\t100.00 \t66.67\n","5 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t50.00 \t\t\t75.00 \t\t100.00 \t\t66.67 \t80.00\n","7 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","9 \t\t50.00 \t\t\t50.00 \t\t66.67 \t\t66.67 \t66.67\n","10 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t60.00 \t\t\t82.50 \t\t86.67 \t\t93.33 \t88.48\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s28\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t50.00 \t\t\t50.00 \t\t100.00 \t\t33.33 \t50.00\n","3 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","4 \t\t25.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","5 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t75.00 \t\t\t75.00 \t\t50.00 \t\t100.00 \t66.67\n","7 \t\t75.00 \t\t\t75.00 \t\t100.00 \t\t50.00 \t66.67\n","8 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","9 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t60.00 \t\t\t87.50 \t\t92.50 \t\t88.33 \t86.90\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s29\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","3 \t\t50.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","4 \t\t75.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","5 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","7 \t\t50.00 \t\t\t75.00 \t\t100.00 \t\t66.67 \t80.00\n","8 \t\t75.00 \t\t\t75.00 \t\t100.00 \t\t75.00 \t85.71\n","9 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t62.50 \t\t\t85.00 \t\t88.33 \t\t94.17 \t89.71\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s30\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","3 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","4 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","5 \t\t50.00 \t\t\t75.00 \t\t75.00 \t\t75.00 \t75.00\n","6 \t\t25.00 \t\t\t75.00 \t\t100.00 \t\t50.00 \t66.67\n","7 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","8 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","9 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t25.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t67.50 \t\t\t92.50 \t\t94.17 \t\t92.50 \t92.17\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s31\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","2 \t\t50.00 \t\t\t75.00 \t\t100.00 \t\t50.00 \t66.67\n","3 \t\t25.00 \t\t\t50.00 \t\t100.00 \t\t33.33 \t50.00\n","4 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","5 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","6 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","7 \t\t25.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","8 \t\t75.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","9 \t\t100.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t67.50 \t\t\t85.00 \t\t90.00 \t\t88.33 \t85.67\n","----------------------------------------------------------------------------------------------------\n","\n","\n","----------------------------------------------------------------------------------------------------\n","Subject No:  s32\n","----------------------------------------------------------------------------------------------------\n","\n","Fold\tAccuracy_with_all_features\tAccuracy\tPrecision\tRecall\tF1-Score\n","1 \t\t50.00 \t\t\t75.00 \t\t75.00 \t\t100.00 \t85.71\n","2 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","3 \t\t75.00 \t\t\t75.00 \t\t100.00 \t\t75.00 \t85.71\n","4 \t\t50.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","5 \t\t75.00 \t\t\t75.00 \t\t66.67 \t\t100.00 \t80.00\n","6 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","7 \t\t50.00 \t\t\t50.00 \t\t66.67 \t\t66.67 \t66.67\n","8 \t\t75.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","9 \t\t50.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","10 \t\t25.00 \t\t\t100.00 \t\t100.00 \t\t100.00 \t100.00\n","----------------------------------------------------------------------------------------------------\n","Total \t\t55.00 \t\t\t85.00 \t\t87.50 \t\t94.17 \t89.81\n","----------------------------------------------------------------------------------------------------\n","\n","\n"]}],"source":["for i in range(20,32):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31NdZ0Tja4ao"},"outputs":[],"source":["for i in range(8,12):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haj9GzL5kdir"},"outputs":[],"source":["for i in range(24, 32):\n","  print('-'*100)\n","  print(\"Subject No: \", subject_names[i])\n","  print('-'*100)\n","  allFeatures, allClasses = drive(subject_names[i])\n","  main_code(allFeatures, allClasses)"]},{"cell_type":"markdown","metadata":{"id":"1hzei03Hitd1"},"source":["**Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1643962283215,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"PpC5h5t1s32y","outputId":"cb17bd6b-e909-4dd6-9c69-476ea16c4d93"},"outputs":[{"name":"stdout","output_type":"stream","text":["32\n","80.234375\n","6.741875173820337\n"]}],"source":["import numpy as np\n","accuracy = [87.50, 75.00, 82.50, 72.50, 70.00, 80.00, 87.50, 75.00, 70.00, 82.50, 72.50, 90.00, 90.00, 82.50, 80.00, 87.50, 77.50, 80.00, 72.50, 82.50,\\\n","            80.00, 72.50, 92.50, 90.00, 72.50, 70.00, 72.50, 87.50, 80.00, 85.00, 85.00, 82.50]\n","print(len(accuracy))\n","accuracy = np.array(accuracy)\n","print(np.mean(accuracy))\n","print(np.std(accuracy))"]},{"cell_type":"markdown","metadata":{"id":"CnCh3SgQQ1qh"},"source":["**Precision**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1643962732723,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"D_0mgcIcij3W","outputId":"1cea0179-422e-4eb0-ffb4-5b802d1838f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["32\n","83.61978125\n","5.899005656328738\n"]}],"source":["precision = [83.33, 80.00, 85.00, 78.333, 76.67, 80.00, 91.67, 85.83, 80.83, 85.83, 70.00, 89.17, 90.00, 85.83, 86.67, 87.50, 86.67, 83.33, 73.33,\\\n","             84.17, 81.67, 78.33, 95.00, 89.17, 78.33, 71.67, 77.50, 88.33, 85.00, 91.67, 89.17, 85.83]\n","print(len(precision))\n","precision = np.array(precision)\n","print(np.mean(precision))\n","print(np.std(precision))"]},{"cell_type":"markdown","metadata":{"id":"vYHYosARiwOS"},"source":["**Recall or sensitivity**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1643962970277,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"T_QkO7J2lfik","outputId":"d4e7228b-7cdb-4c10-890a-92453dac851f"},"outputs":[{"name":"stdout","output_type":"stream","text":["87.70906250000002\n"]},{"data":{"text/plain":["7.620516452058466"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["recall = [95.00, 87.50, 80.00, 71.67, 74.17, 86.67, 91.67, 83.33, 72.50, 86.67, 77.5, 100.00, 100.00, 93.33, 82.50, 90.00, 83.33, 94.17, 85.00, 96.67,\\\n","          96.67, 86.67, 90.00, 100.00, 87.50, 80.00, 90.00, 93.33, 89.17, 81.67, 85.83, 94.17]\n","recall = np.array(recall)\n","print(np.mean(recall))\n","np.std(recall)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4cX-xrJ0Riv"},"outputs":[],"source":["[95.00, 87.50, 80.00, 71.67, 74.17, 86.67, 91.67, 83.33, 72.50, 86.67, 77.5, 100.00, 100.00, 93.33, 82.50, 90.00, 83.33, 94.17, 85.00, 96.67, 96.67, 86.67, 90.00, 100.00, 87.50, 80.00, 90.00, 93.33, 89.17, 81.67, 85.83, 94.17]"]},{"cell_type":"markdown","metadata":{"id":"NLYj-mQVe_Xf"},"source":["**f1-Score**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1643965376157,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"},"user_tz":-330},"id":"e38D0Ecsmr-U","outputId":"addff756-42e3-4948-8a83-bdadcacd54cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["83.00874999999999\n","6.722352522554884\n"]}],"source":["f1 = [87.67, 78.90, 81.77, 72.00, 71.67, 81.00, 90.48, 80.4, 71.81, 84.24, 70.24, 93.71, 93.81, 88.38, 80.24, 85.24, 81.33, 85.90, 76.79, 88.38, 87.62,\\\n","      76.57, 91.67, 92.00, 80.05, 71.67, 80.05, 89.33, 84.38, 84.33, 86.17, 88.48]\n","f1 = np.array(f1)\n","print(np.mean(f1))\n","print(np.std(f1))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"STEP: 4B Part-2-- Subject Independent GA based feature selection from optimal channels + SVM classifier for Arousal class.ipynb","provenance":[{"file_id":"1UySsCj4cluAeUc3Wqtl2ZVbgvvb4onVI","timestamp":1643992635081},{"file_id":"1HYesvxoVn-s8CHSqqMROc-FaB65YAOUe","timestamp":1640784913180},{"file_id":"1HLyqqmh4klsQ8H-0e4Eq499vAupq5dS0","timestamp":1639306093118},{"file_id":"1KXk5nWjSgHzZ6ccp66jHRDZI4bJMslHn","timestamp":1639196338642},{"file_id":"1yUzEFwdmCNH_qb7NPCgLlYElOhT12erL","timestamp":1634187566670},{"file_id":"1SPeDVHCHi4uFuamkolvaep7nGU7mOyiv","timestamp":1634152149383},{"file_id":"1aD6aXmoab59Jb7cxRTbtGKDfdiG7ianV","timestamp":1634151736936},{"file_id":"1luLhv4lQ-SruSeQqeX8bZnYPR-_TYxDk","timestamp":1634111894346},{"file_id":"11OHLRm15JjC9C-Y-R_LGBacQkwDFduQh","timestamp":1633972949871},{"file_id":"1qrk7-0VYo258YnzRzG4ztcbrT3zWq-HG","timestamp":1633964775809}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}